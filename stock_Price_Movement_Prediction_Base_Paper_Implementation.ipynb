{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraAsgharQ/Stock-Price-Prediction/blob/main/stock_Price_Movement_Prediction_Base_Paper_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD2VEYP762cK",
        "outputId": "79065eb7-87b8-45e8-fd86-e10400bc493d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: pandas-ta in /usr/local/lib/python3.12/dist-packages (0.4.71b0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.6)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from pandas-ta) (0.61.2)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pandas-ta) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->pandas-ta) (0.44.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.10.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance pandas-ta scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Setup for the data fetching (Assume this was in the first cell) ---\n",
        "TICKER = \"^KSE\"\n",
        "START_DATE = datetime(2010, 1, 1)\n",
        "END_DATE = datetime(2023, 10, 1)\n",
        "\n",
        "print(f\"Fetching data for {TICKER}...\")\n",
        "\n",
        "data = yf.download(TICKER, start=START_DATE, end=END_DATE)\n",
        "\n",
        "if data.empty:\n",
        "    print(\"FATAL ERROR: Data could not be fetched with any ticker. Please verify the ticker is active on Yahoo Finance.\")\n",
        "else:\n",
        "    print(f\"Data fetched successfully. Total rows: {len(data)}\")\n",
        "    print(\"Data Columns after fetch:\", data.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBxde3GV7A-5",
        "outputId": "c3a1dd18-68c3-4aac-f84e-37c7d55ab6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for ^KSE...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3913335297.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(TICKER, start=START_DATE, end=END_DATE)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data fetched successfully. Total rows: 2809\n",
            "Data Columns after fetch: [('Close', '^KSE'), ('High', '^KSE'), ('Low', '^KSE'), ('Open', '^KSE'), ('Volume', '^KSE')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install TA-Lib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUnn8Wth9z2g",
        "outputId": "725f5085-0e67-4a0f-abbc-c44915778f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TA-Lib\n",
            "  Downloading ta_lib-0.6.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.12/dist-packages (from TA-Lib) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from TA-Lib) (2.2.6)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build->TA-Lib) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build->TA-Lib) (1.2.0)\n",
            "Downloading ta_lib-0.6.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: TA-Lib\n",
            "Successfully installed TA-Lib-0.6.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import talib as ta\n",
        "import numpy as np\n",
        "\n",
        "data.columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
        "data = data.sort_index()\n"
      ],
      "metadata": {
        "id": "UjRp8NSg7YnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- TECHNICAL INDICATOR CALCULATIONS -----------------\n",
        "\n",
        "\n",
        "data.index = pd.to_datetime(data.index)\n",
        "\n",
        "\n",
        "# --- 1. Moving Averages and Related Indicators (9 Features) ---\n",
        "\n",
        "# Auxiliary Moving Averages (Needed for other indicators)\n",
        "data['MA_5'] = ta.SMA(data['Close'], timeperiod=5)\n",
        "data['MA_10'] = ta.SMA(data['Close'], timeperiod=10)\n",
        "data['MA_14'] = ta.SMA(data['Close'], timeperiod=14)\n",
        "\n",
        "# 1. Exponential Moving Average (EMA) - Feature 1\n",
        "data['EMA_12'] = ta.EMA(data['Close'], timeperiod=12)\n",
        "\n",
        "# 2. Weighted Moving Average (WMA) - Feature 2\n",
        "data['WMA_14'] = ta.WMA(data['Close'], timeperiod=14)\n",
        "\n",
        "# 3. Disparity 5 (Close/MA5 * 100) - Feature 3 [cite: 94]\n",
        "data['Disparity 5'] = (data['Close'] / data['MA_5']) * 100\n",
        "\n",
        "# 4. Disparity 14 (Close/MA14 * 100) - Feature 4 [cite: 94]\n",
        "data['Disparity 14'] = (data['Close'] / data['MA_14']) * 100\n",
        "\n",
        "# 5. Price Oscillator (OSCP) (MA5 - MA10) - Feature 5 [cite: 94]\n",
        "data['OSCP'] = data['MA_5'] - data['MA_10']\n",
        "\n",
        "# 6. Upper Band (Bollinger Band) - Feature 6\n",
        "# 7. Lower Band (Bollinger Band) - Feature 7\n",
        "data['Upper_BB'], data['Middle_BB'], data['Lower_BB'] = ta.BBANDS(\n",
        "    data['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0\n",
        ")\n",
        "\n",
        "# 8. MACD - Feature 8\n",
        "# 9. Signal Line - Feature 9\n",
        "data['MACD'], data['MACD_Signal'], _ = ta.MACD(\n",
        "    data['Close'], fastperiod=12, slowperiod=26, signalperiod=9\n",
        ")\n",
        "\n",
        "# --- 2. Momentum and Volatility Indicators (10 Features) ---\n",
        "\n",
        "# 10. Relative Strength Index (RSI) - Feature 10\n",
        "data['RSI'] = ta.RSI(data['Close'], timeperiod=14)\n",
        "\n",
        "# 11. Rate of Change (ROC) - Feature 11\n",
        "data['ROC'] = ta.ROC(data['Close'], timeperiod=10)\n",
        "\n",
        "# 12. Momentum (close - close_4) - Feature 12 [cite: 94]\n",
        "data['Momentum'] = data['Close'].diff(4)\n",
        "\n",
        "# 13. Williams %R (%R) - Feature 13\n",
        "data['%R'] = ta.WILLR(data['High'], data['Low'], data['Close'], timeperiod=14)\n",
        "\n",
        "# 14. Commodity Channel Index (CCI) - Feature 14\n",
        "data['CCI'] = ta.CCI(data['High'], data['Low'], data['Close'], timeperiod=14)\n",
        "\n",
        "# 15. Average True Range (ATR) - Feature 15\n",
        "data['ATR'] = ta.ATR(data['High'], data['Low'], data['Close'], timeperiod=14)\n",
        "\n",
        "# 16. Stochastic %K (%K) - Feature 16\n",
        "data['%K'], data['%D'] = ta.STOCH(\n",
        "    data['High'], data['Low'], data['Close'],\n",
        "    fastk_period=5, slowk_period=3, slowd_period=3\n",
        ")\n",
        "# 17. Stochastic %D (%D) - Feature 17\n",
        "# %D is calculated in the previous step.\n",
        "\n",
        "# --- 3. Volume Indicators (3 Features) ---\n",
        "\n",
        "# 18. On-Balance Volume (OBV) - Feature 18\n",
        "data['OBV'] = ta.OBV(data['Close'], data['Volume'])\n",
        "\n",
        "# 19. Chaikin Oscillator (ADOSC) - Feature 19\n",
        "# TA-Lib ADOSC implements Chaikin Oscillator (3/10 periods are common defaults)\n",
        "data['Chaikin_Oscillator'] = ta.ADOSC(data['High'], data['Low'], data['Close'], data['Volume'], fastperiod=3, slowperiod=10)\n",
        "\n",
        "# 20. Money Flow Index (MFI) - Feature 20\n",
        "data['MFI'] = ta.MFI(data['High'], data['Low'], data['Close'], data['Volume'], timeperiod=14)\n",
        "\n",
        "\n",
        "# --- 4. Pivot Points (5 Features) ---\n",
        "\n",
        "# 21. Pivot Point (PP) - Feature 21 [cite: 94]\n",
        "data['PP'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
        "\n",
        "# 22. First Support (S1) - Feature 22 [cite: 94]\n",
        "data['S1'] = (data['PP'] * 2) - data['High']\n",
        "\n",
        "# 23. Second Support (S2) - Feature 23 [cite: 94]\n",
        "data['S2'] = data['PP'] - (data['High'] - data['Low'])\n",
        "\n",
        "# 24. First Resistance (R1) - Feature 24 [cite: 94]\n",
        "# Note: The paper's formula for R1 uses 'lou' (low), which is a common typo for 'low'.\n",
        "data['R1'] = (data['PP'] * 2) - data['Low']\n",
        "\n",
        "# 25. Second Resistance (R2) - Feature 25 [cite: 94]\n",
        "data['R2'] = data['PP'] + (data['High'] - data['Low'])\n",
        "\n",
        "\n",
        "# --- 5. Anomaly Features (2 Features) ---\n",
        "\n",
        "# 26. Day of Week Anomaly - Feature 26 [cite: 97]\n",
        "# Formula: close / (close.groupby(Day of W).trans(mean))\n",
        "data['Day of Week Anomaly'] = data['Close'] / data['Close'].groupby(data.index.dayofweek).transform('mean')\n",
        "\n",
        "# 27. Week of Month Anomaly - Feature 27 [cite: 97]\n",
        "# Formula: close / (close.groupby(W of M).trans(mean))\n",
        "# Week of Month (1-5) calculation:\n",
        "data['Week of Month'] = (data.index.day - 1) // 7 + 1\n",
        "data['Week of Month Anomaly'] = data['Close'] / data['Close'].groupby(data['Week of Month']).transform('mean')\n",
        "\n",
        "# --- Final Cleanup ---\n",
        "\n",
        "# Drop the temporary/auxiliary columns (MA_5, MA_10, MA_14, Middle_BB, MACD_Signal, Week of Month)\n",
        "data = data.drop(columns=['MA_5', 'MA_10', 'MA_14', 'Middle_BB', 'MACD_Signal', 'Week of Month'])\n",
        "\n",
        "# Drop all rows where any indicator value is NaN\n",
        "data = data.dropna()\n",
        "\n",
        "# Check the final count of features and rows\n",
        "print(f\"Total columns (5 OHLCV + 27 Features): {data.shape[1]}\")\n",
        "print(f\"DataFrame Shape after adding 27 features and dropping NaNs: {data.shape}\")\n",
        "print(\"\\nFinal list of technical feature columns:\")\n",
        "# Print only the feature columns (skipping the first 5 base columns)\n",
        "print(data.columns[5:].tolist())\n",
        "print(\"\\nFirst 5 rows of the feature-rich data:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD2l-JcI9ydv",
        "outputId": "b72999af-4159-4d26-eb01-b431ffb3b80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total columns (5 OHLCV + 27 Features): 31\n",
            "DataFrame Shape after adding 27 features and dropping NaNs: (2776, 31)\n",
            "\n",
            "Final list of technical feature columns:\n",
            "['EMA_12', 'WMA_14', 'Disparity 5', 'Disparity 14', 'OSCP', 'Upper_BB', 'Lower_BB', 'MACD', 'RSI', 'ROC', 'Momentum', '%R', 'CCI', 'ATR', '%K', '%D', 'OBV', 'Chaikin_Oscillator', 'MFI', 'PP', 'S1', 'S2', 'R1', 'R2', 'Day of Week Anomaly', 'Week of Month Anomaly']\n",
            "\n",
            "First 5 rows of the feature-rich data:\n",
            "                  Close         High          Low         Open  Volume  \\\n",
            "Date                                                                     \n",
            "2010-02-23  9823.570312  9973.589844  9806.370117  9953.200195       0   \n",
            "2010-02-24  9686.179688  9850.580078  9673.179688  9850.580078       0   \n",
            "2010-02-25  9667.169922  9741.230469  9575.129883  9701.219727       0   \n",
            "2010-02-26  9657.790039  9716.969727  9653.769531  9691.839844       0   \n",
            "2010-03-01  9498.559570  9684.519531  9471.799805  9658.450195       0   \n",
            "\n",
            "                 EMA_12       WMA_14  Disparity 5  Disparity 14        OSCP  \\\n",
            "Date                                                                          \n",
            "2010-02-23  9823.851797  9837.431315    99.357146    100.287001   53.748047   \n",
            "2010-02-24  9802.671473  9822.860975    98.327386     98.818876   27.594043   \n",
            "2010-02-25  9781.825080  9804.889909    98.578985     98.596528  -10.212891   \n",
            "2010-02-26  9762.742766  9785.291620    98.977551     98.581254  -44.677930   \n",
            "2010-03-01  9722.099198  9745.528702    98.261091     97.176567 -104.849023   \n",
            "\n",
            "            ...  OBV  Chaikin_Oscillator  MFI           PP           S1  \\\n",
            "Date        ...                                                           \n",
            "2010-02-23  ...  0.0                 0.0  0.0  9867.843424  9762.097005   \n",
            "2010-02-24  ...  0.0                 0.0  0.0  9736.646484  9622.712891   \n",
            "2010-02-25  ...  0.0                 0.0  0.0  9661.176758  9581.123047   \n",
            "2010-02-26  ...  0.0                 0.0  0.0  9676.176432  9635.383138   \n",
            "2010-03-01  ...  0.0                 0.0  0.0  9551.626302  9418.733073   \n",
            "\n",
            "                     S2           R1            R2  Day of Week Anomaly  \\\n",
            "Date                                                                      \n",
            "2010-02-23  9700.623698  9929.316732  10035.063151             0.326693   \n",
            "2010-02-24  9559.246094  9800.113281   9914.046875             0.322010   \n",
            "2010-02-25  9495.076172  9747.223633   9827.277344             0.321458   \n",
            "2010-02-26  9612.976237  9698.583333   9739.376628             0.320693   \n",
            "2010-03-01  9338.906576  9631.452799   9764.346029             0.316579   \n",
            "\n",
            "            Week of Month Anomaly  \n",
            "Date                               \n",
            "2010-02-23               0.327825  \n",
            "2010-02-24               0.323240  \n",
            "2010-02-25               0.322605  \n",
            "2010-02-26               0.322292  \n",
            "2010-03-01               0.316078  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the daily percentage change (future price relative to current price)\n",
        "# Using .shift(-1) to look forward: the price on T+1 is placed on the row for T.\n",
        "data['Future Close Price'] = data['Close'].shift(-1)\n",
        "\n",
        "# Creating the target variable: 'Price Movement'\n",
        "# 1 if the future close price is greater than the current close price.\n",
        "# 0 otherwise.\n",
        "data['Price Movement'] = np.where(data['Future Close Price'] > data['Close'], 1, 0)\n",
        "\n",
        "# Cleaning up the DataFrame\n",
        "# Drop the 'Future Close Price' column as it is only an intermediate step\n",
        "# and should not be used as a feature in the model.\n",
        "data = data.drop(columns=['Future Close Price'])\n",
        "\n",
        "# Drop the last row, which will have a NaN value in 'Price Movement'\n",
        "# because there is no T+1 close price to calculate the movement.\n",
        "data = data.dropna()\n",
        "\n",
        "print(\"Target variable 'Price Movement' created.\")\n",
        "print(f\"Final DataFrame Shape: {data.shape}\")\n",
        "\n",
        "# Check the distribution of the target variable\n",
        "movement_counts = data['Price Movement'].value_counts()\n",
        "print(\"\\nTarget Variable Distribution:\")\n",
        "print(movement_counts)\n",
        "print(f\"Proportion of 'Up' days (1): {movement_counts[1] / len(data):.2f}\")\n",
        "\n",
        "print(\"\\nFirst 5 rows with the new target variable:\")\n",
        "print(data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es09dpNi-TOM",
        "outputId": "127438e4-5a37-41b2-c5d8-04852ef659a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target variable 'Price Movement' created.\n",
            "Final DataFrame Shape: (2776, 32)\n",
            "\n",
            "Target Variable Distribution:\n",
            "Price Movement\n",
            "1    1487\n",
            "0    1289\n",
            "Name: count, dtype: int64\n",
            "Proportion of 'Up' days (1): 0.54\n",
            "\n",
            "First 5 rows with the new target variable:\n",
            "                   Close          High           Low          Open  Volume  \\\n",
            "Date                                                                         \n",
            "2021-08-31  47419.738281  47596.039062  47349.488281  47365.699219       0   \n",
            "2021-09-01  47413.460938  47628.589844  47355.140625  47419.738281       0   \n",
            "2021-09-02  46903.058594  47489.398438  46874.640625  47413.460938       0   \n",
            "2021-09-03  46957.468750  47113.421875  46879.281250  46903.058594       0   \n",
            "2021-09-30  44899.601562  44899.601562  43972.089844  44366.738281       0   \n",
            "\n",
            "                  EMA_12        WMA_14  Disparity 5  Disparity 14        OSCP  \\\n",
            "Date                                                                            \n",
            "2021-08-31  47435.595943  47444.524777   100.074943    100.043665  -79.084375   \n",
            "2021-09-01  47432.190558  47446.447396   100.155728     99.988536 -173.639062   \n",
            "2021-09-02  47350.785640  47377.668936    99.270570     98.982889 -230.142188   \n",
            "2021-09-03  47290.275349  47320.662500    99.461118     99.144536 -201.719531   \n",
            "2021-09-30  46922.479382  46992.257515    96.106344     95.125309 -373.678125   \n",
            "\n",
            "            ...  Chaikin_Oscillator  MFI            PP            S1  \\\n",
            "Date        ...                                                        \n",
            "2021-08-31  ...        2.235174e-08  0.0  47455.088542  47314.138021   \n",
            "2021-09-01  ...        2.235174e-08  0.0  47465.730469  47302.871094   \n",
            "2021-09-02  ...        2.235174e-08  0.0  47089.032552  46688.666667   \n",
            "2021-09-03  ...        2.235174e-08  0.0  46983.390625  46853.359375   \n",
            "2021-09-30  ...        2.235174e-08  0.0  44590.430990  44281.260417   \n",
            "\n",
            "                      S2            R1            R2  Day of Week Anomaly  \\\n",
            "Date                                                                        \n",
            "2021-08-31  47208.537760  47560.688802  47701.639323             1.576991   \n",
            "2021-09-01  47192.281250  47576.320312  47739.179688             1.576226   \n",
            "2021-09-02  46474.274740  47303.424479  47703.790365             1.559645   \n",
            "2021-09-03  46749.250000  47087.500000  47217.531250             1.559250   \n",
            "2021-09-30  43662.919271  45208.772135  45517.942708             1.493025   \n",
            "\n",
            "            Week of Month Anomaly  Price Movement  \n",
            "Date                                               \n",
            "2021-08-31               1.565753               0  \n",
            "2021-09-01               1.577749               0  \n",
            "2021-09-02               1.560764               1  \n",
            "2021-09-03               1.562575               0  \n",
            "2021-09-30               1.482540               0  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Define Features (X) and Target (y)\n",
        "# Features (X) are all columns EXCEPT the 'Price Movement' target variable.\n",
        "# We must exclude the original OHLCV columns and only keep the technical features.\n",
        "# The original OHLCV columns (Close, High, Low, Open, Volume) are not typically used as direct features.\n",
        "# Based on the feature list provided in your output, the features start from 'SMA_50'.\n",
        "feature_cols = data.columns[5:-1] # Selects from 'SMA_50' up to (but not including) 'Price Movement'\n",
        "\n",
        "X = data[feature_cols]\n",
        "y = data['Price Movement']\n",
        "\n",
        "# 2. Time-Based Train-Test Split (80% Train, 20% Test)\n",
        "# For time series, we slice the data based on index position, not random selection.\n",
        "split_ratio = 0.8\n",
        "split_index = int(np.floor(split_ratio * len(data)))\n",
        "\n",
        "X_train = X[:split_index]\n",
        "X_test = X[split_index:]\n",
        "y_train = y[:split_index]\n",
        "y_test = y[split_index:]\n",
        "\n",
        "# 3. Feature Scaling\n",
        "# Scaling is crucial for ANN and SVM and is applied AFTER the split to prevent data leakage.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler ONLY on the training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the transformation to both training and testing data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert the scaled arrays back to DataFrames for easier handling (optional but helpful)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X.columns)\n",
        "\n",
        "# 4. Final Verification\n",
        "print(\"--- Data Split and Scaling Complete ---\")\n",
        "print(f\"Total rows in data: {len(data)}\")\n",
        "print(f\"X_train (Train Features) shape: {X_train_scaled.shape}\")\n",
        "print(f\"y_train (Train Target) shape: {y_train.shape}\")\n",
        "print(f\"X_test (Test Features) shape: {X_test_scaled.shape}\")\n",
        "print(f\"y_test (Test Target) shape: {y_test.shape}\")\n",
        "print(\"\\nFirst 5 rows of scaled training features:\")\n",
        "print(X_train_scaled.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyQTWgd7-fDR",
        "outputId": "095d1972-70b7-412b-ddba-8d276ee7ea53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Split and Scaling Complete ---\n",
            "Total rows in data: 2776\n",
            "X_train (Train Features) shape: (2220, 26)\n",
            "y_train (Train Target) shape: (2220,)\n",
            "X_test (Test Features) shape: (556, 26)\n",
            "y_test (Test Target) shape: (556,)\n",
            "\n",
            "First 5 rows of scaled training features:\n",
            "              EMA_12    WMA_14  Disparity 5  Disparity 14      OSCP  Upper_BB  \\\n",
            "Date                                                                            \n",
            "2010-02-23 -1.419438 -1.419482    -0.672445     -0.050257  0.074972 -1.426499   \n",
            "2010-02-24 -1.421097 -1.420623    -1.579203     -0.710247 -0.008707 -1.426499   \n",
            "2010-02-25 -1.422730 -1.422031    -1.357657     -0.810203 -0.129670 -1.426500   \n",
            "2010-02-26 -1.424225 -1.423566    -1.006699     -0.817069 -0.239940 -1.426713   \n",
            "2010-03-01 -1.427409 -1.426680    -1.637580     -1.448541 -0.432456 -1.425921   \n",
            "\n",
            "            Lower_BB      MACD       RSI       ROC  ...       OBV  \\\n",
            "Date                                                ...             \n",
            "2010-02-23 -1.410503 -0.158633  0.164336 -0.149950  ... -3.928555   \n",
            "2010-02-24 -1.410528 -0.189965 -0.485846 -0.486688  ... -3.928555   \n",
            "2010-02-25 -1.410521 -0.218862 -0.564732 -0.386916  ... -3.928555   \n",
            "2010-02-26 -1.409850 -0.243537 -0.605123 -0.618285  ... -3.928555   \n",
            "2010-03-01 -1.411366 -0.295504 -1.197375 -1.097294  ... -3.928555   \n",
            "\n",
            "            Chaikin_Oscillator       MFI        PP        S1        S2  \\\n",
            "Date                                                                     \n",
            "2010-02-23           -0.073098 -3.228432 -1.422786 -1.426588 -1.427181   \n",
            "2010-02-24           -0.073098 -3.228432 -1.433071 -1.437582 -1.438400   \n",
            "2010-02-25           -0.073098 -3.228432 -1.438988 -1.440862 -1.443492   \n",
            "2010-02-26           -0.073098 -3.228432 -1.437812 -1.436582 -1.434136   \n",
            "2010-03-01           -0.073098 -3.228432 -1.447576 -1.453671 -1.455886   \n",
            "\n",
            "                  R1        R2  Day of Week Anomaly  Week of Month Anomaly  \n",
            "Date                                                                        \n",
            "2010-02-23 -1.422036 -1.418116            -1.425936              -1.423238  \n",
            "2010-02-24 -1.432103 -1.427487            -1.436974              -1.434046  \n",
            "2010-02-25 -1.436224 -1.434207            -1.438275              -1.435541  \n",
            "2010-02-26 -1.440014 -1.441014            -1.440079              -1.436279  \n",
            "2010-03-01 -1.445245 -1.439080            -1.449775              -1.450928  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Convert scaled DataFrames to numpy arrays for Keras/ANN\n",
        "X_train_array = X_train_scaled.values\n",
        "X_test_array = X_test_scaled.values\n",
        "\n",
        "# Define the number of features\n",
        "n_features = X_train_array.shape[1]\n",
        "\n",
        "# --------------------------------------------\n",
        "# ---  Artificial Neural Network (ANN) ---\n",
        "# --------------------------------------------\n",
        "\n",
        "print(\"--- Training Artificial Neural Network (ANN) ---\")\n",
        "\n",
        "ann_model = Sequential([\n",
        "    # Input layer with 128 neurons and ReLU activation\n",
        "    Dense(128, activation='relu', input_shape=(n_features,)),\n",
        "    # Hidden layer with 64 neurons\n",
        "    Dense(64, activation='relu'),\n",
        "    # Output layer with 1 neuron (for binary classification) and Sigmoid activation\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ann_model.fit(X_train_array, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict and evaluate\n",
        "ann_pred_proba = ann_model.predict(X_test_array, verbose=0)\n",
        "ann_pred = (ann_pred_proba > 0.5).astype(int)\n",
        "ann_accuracy = accuracy_score(y_test, ann_pred)\n",
        "print(f\"ANN Test Accuracy: {ann_accuracy:.4f}\")\n",
        "print(\"ANN Classification Report:\\n\", classification_report(y_test, ann_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7hH5vZp-p_P",
        "outputId": "7e0a36ff-eea2-470c-cb48-4fa9b1c21e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Artificial Neural Network (ANN) ---\n",
            "ANN Test Accuracy: 0.5216\n",
            "ANN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.15      0.23       263\n",
            "           1       0.53      0.86      0.65       293\n",
            "\n",
            "    accuracy                           0.52       556\n",
            "   macro avg       0.50      0.50      0.44       556\n",
            "weighted avg       0.51      0.52      0.45       556\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# --- Support Vector Machine (SVM) ---\n",
        "# --------------------------------------------\n",
        "print(\"--- Training Support Vector Machine (SVM) ---\")\n",
        "\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "svm_pred = svm_model.predict(X_test_scaled)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "print(f\"SVM Test Accuracy: {svm_accuracy:.4f}\")\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLQS_E6uKX_V",
        "outputId": "741619d8-04c9-42e9-a5e1-f5ffa727432a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Support Vector Machine (SVM) ---\n",
            "SVM Test Accuracy: 0.5378\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.40      0.45       263\n",
            "           1       0.55      0.66      0.60       293\n",
            "\n",
            "    accuracy                           0.54       556\n",
            "   macro avg       0.53      0.53      0.53       556\n",
            "weighted avg       0.53      0.54      0.53       556\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# ---  Random Forest (RF) ---\n",
        "# --------------------------------------------\n",
        "print(\"--- Training Random Forest (RF) ---\")\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "rf_pred = rf_model.predict(X_test_scaled)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "print(f\"RF Test Accuracy: {rf_accuracy:.4f}\")\n",
        "print(\"RF Classification Report:\\n\", classification_report(y_test, rf_pred, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BMJ2Gf_K4IH",
        "outputId": "776b0f4a-078c-4b76-c8b5-a6ca51ba568a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Random Forest (RF) ---\n",
            "RF Test Accuracy: 0.5342\n",
            "RF Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.61      0.55       263\n",
            "           1       0.57      0.47      0.51       293\n",
            "\n",
            "    accuracy                           0.53       556\n",
            "   macro avg       0.54      0.54      0.53       556\n",
            "weighted avg       0.54      0.53      0.53       556\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# ---  Long Short-Term Memory (LSTM) ---\n",
        "# --------------------------------------------\n",
        "\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "\n",
        "# --- 1. Reshape Data for LSTM ---\n",
        "# LSTM expects input data in 3D format: [samples, time_steps, features].\n",
        "# For predicting the next day (time_steps=1), we simply add an axis.\n",
        "# X_train_scaled.shape is (810, 31). Reshaping to (810, 1, 31).\n",
        "\n",
        "X_train_lstm = X_train_scaled.values.reshape(\n",
        "    X_train_scaled.shape[0], 1, X_train_scaled.shape[1]\n",
        ")\n",
        "X_test_lstm = X_test_scaled.values.reshape(\n",
        "    X_test_scaled.shape[0], 1, X_test_scaled.shape[1]\n",
        ")\n",
        "\n",
        "print(f\"X_train reshaped for LSTM: {X_train_lstm.shape}\")\n",
        "print(f\"X_test reshaped for LSTM: {X_test_lstm.shape}\")\n",
        "\n",
        "# Define the number of features\n",
        "n_features = X_train_lstm.shape[2]\n",
        "\n",
        "print(\"\\n--- Training Long Short-Term Memory (LSTM) ---\")\n",
        "\n",
        "# Simple LSTM Architecture\n",
        "lstm_model = Sequential([\n",
        "    # LSTM layer: 50 units, input shape (time_steps, features)\n",
        "    LSTM(50, input_shape=(X_train_lstm.shape[1], n_features), activation='relu'),\n",
        "    # Dense hidden layer\n",
        "    Dense(25, activation='relu'),\n",
        "    # Output layer: 1 neuron for binary classification (0 or 1)\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "lstm_pred_proba = lstm_model.predict(X_test_lstm, verbose=0)\n",
        "lstm_pred = (lstm_pred_proba > 0.5).astype(int)\n",
        "lstm_accuracy = accuracy_score(y_test, lstm_pred)\n",
        "\n",
        "print(f\"LSTM Test Accuracy: {lstm_accuracy:.4f}\")\n",
        "print(\"LSTM Classification Report:\\n\", classification_report(y_test, lstm_pred, zero_division=0))"
      ],
      "metadata": {
        "id": "nFJjQAso-5AN",
        "outputId": "91d633e7-d0c9-4cf4-b0ff-38515cb0112d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train reshaped for LSTM: (2220, 1, 26)\n",
            "X_test reshaped for LSTM: (556, 1, 26)\n",
            "\n",
            "--- Training Long Short-Term Memory (LSTM) ---\n",
            "LSTM Test Accuracy: 0.5270\n",
            "LSTM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.17      0.25       263\n",
            "           1       0.53      0.85      0.65       293\n",
            "\n",
            "    accuracy                           0.53       556\n",
            "   macro avg       0.52      0.51      0.45       556\n",
            "weighted avg       0.52      0.53      0.46       556\n",
            "\n"
          ]
        }
      ]
    }
  ]
}